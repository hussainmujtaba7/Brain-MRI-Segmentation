{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#install dependencies\n!pip install albumentations==0.4.6","metadata":{"_uuid":"7dac199c-7de1-4cb4-9274-da73fe09226a","_cell_guid":"5ee3a324-352f-417b-b91a-67219e2e9d3a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set true for model to train \n#reduce the barch size and num of models to set true , if CUDA out of memory error\nunet=True\natten_unet=True\nuR2net=False\nuA2net=False #uR2net attention\nu3net =False","metadata":{"_uuid":"ee05f6d8-d367-409b-8c36-357e40c40258","_cell_guid":"c2703071-70ad-439f-a19e-816059b3cd34","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imports \nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport time\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2, ToTensor\nfrom sklearn.model_selection import train_test_split\n\nplt.style.use(\"fivethirtyeight\")\n#set device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"96d74826-2b04-4dd4-b4ec-d2df3e54978c","_cell_guid":"5851cdb6-a737-4bf4-a9a0-357d22c6f8fb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset path variables : used to find path of images and masks\nBASE_PATH= \"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\nBASE_LEN = 89\nEND_LEN = 4\nEND_MASK_LEN = 9\nIMG_SIZE = 512","metadata":{"_uuid":"ebd73f66-f1b0-4571-ace7-87a676a0becb","_cell_guid":"474a09c3-43bf-4a12-8c97-ac2d8ef6924a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions","metadata":{"_uuid":"7a345855-b0e5-426b-8d4b-34af91fe0bcb","_cell_guid":"80f897df-a4f4-4e38-9b4e-d6cc58244143","trusted":true}},{"cell_type":"code","source":"#display augmented images    \ndef show_aug(inputs, nrows=5, ncols=5):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 25:\n        inputs = inputs[:25]\n        \n    for idx in range(len(inputs)):\n    \n        img = inputs[idx].numpy().astype(np.float32)\n        img = img[0,:,:]\n        \n        plt.subplot(nrows, ncols, i_+1)\n        plt.imshow(img); \n        plt.axis('off')\n \n        i_ += 1\n        \n    return plt.show()\n\n#segmentation metric \ndef dice_coef_metric(inputs, target):\n    intersection = 2.0 * (target*inputs).sum()\n    union = target.sum() + inputs.sum()\n    if target.sum() == 0 and inputs.sum() == 0:\n        return 1.0 \n    return intersection/union\n\n#label data used for splitting data so that we can have of each class \ndef pos_neg_diagnosis(mask_path):\n    val = np.max(cv2.imread(mask_path))\n    if val > 0: return 1\n    else: return 0\n    \n#compute IOU\ndef compute_iou(model, loader, threshold=0.5):\n    valloss = 0\n    with torch.no_grad():\n\n        for i_step, (data, target) in enumerate(loader):\n            \n            data = data.to(device)\n            target = target.to(device)\n            \n            outputs = model(data)\n\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += picloss\n\n    return valloss / i_step","metadata":{"_uuid":"86ac50cf-c8f8-4f10-abce-b8eb9d658bdd","_cell_guid":"9d50a014-e258-4fc7-9dd2-2a1912c0e35c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, num_epochs):\n    print(f\"[INFO] Model is initializing... {model_name}\")\n    \n    loss_history = []\n    train_history = []\n    val_history = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        \n        losses = []\n        train_iou = []\n        \n        for i_step, (data, target) in enumerate(tqdm(train_loader)):\n            data = data.to(device)\n            target = target.to(device)\n            \n            outputs = model(data)\n            \n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n            \n            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            \n            loss = train_loss(outputs, target)\n            \n            losses.append(loss.item())\n            train_iou.append(train_dice)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        val_mean_iou = compute_iou(model, val_loader)\n        \n        loss_history.append(np.array(losses).mean())\n        train_history.append(np.array(train_iou).mean())\n        val_history.append(val_mean_iou)\n        \n        print(\"Epoch [%d]\" % (epoch))\n        print(\"Mean loss on train:\", np.array(losses).mean(), \n              \"\\nMean DICE on train:\", np.array(train_iou).mean(), \n              \"\\nMean DICE on validation:\", val_mean_iou)\n        \n    return loss_history, train_history, val_history\n\ndef plot_model_history(model_name,\n                        train_history, val_history, \n                        num_epochs):\n    \n    x = np.arange(num_epochs)\n\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"DICE\", fontsize=15)\n\n    fn = str(int(time.time())) + \".png\"\n    plt.show()\n    \n#segmentation loss\nclass BCEwithDiceLoss(nn.Module):\n    def __init__(self):\n        super(BCEwithDiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #apply sigmoid to inputs\n        inputs = nn.Sigmoid()(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        #calculate dice loss\n        intersection = (inputs * targets).sum()                            \n        dice = 1- (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth) \n        \n       # calculate BCE\n        bce = F.binary_cross_entropy_with_logits(inputs, targets)\n        \n        return dice + bce\n    \n","metadata":{"_uuid":"0b9a34c9-0495-4afe-bcdf-fe02a3356e23","_cell_guid":"d941d0f4-9624-4a9e-b450-8021a2e40bf3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{"_uuid":"55255311-8697-4ea9-ab32-612522645c76","_cell_guid":"1de7dbfb-0ea9-47de-889a-f54e03487144","trusted":true}},{"cell_type":"code","source":"data = []\n\nfor dir_ in os.listdir(BASE_PATH):\n    dir_path = os.path.join(BASE_PATH, dir_)\n    if os.path.isdir(dir_path):\n        for filename in os.listdir(dir_path):\n            img_path = os.path.join(dir_path, filename)\n            data.append([dir_, img_path])\n    else:\n        print(f\"[INFO] This is not a dir --> {dir_path}\")\n        \ndf = pd.DataFrame(data, columns=[\"dir_name\", \"image_path\"])\ndf_imgs = df[~df[\"image_path\"].str.contains(\"mask\")]\ndf_masks = df[df[\"image_path\"].str.contains(\"mask\")]\nimgs = sorted(df_imgs[\"image_path\"].values, key= lambda x: int(x[BASE_LEN: -END_LEN]))\nmasks = sorted(df_masks[\"image_path\"].values, key=lambda x: int(x[BASE_LEN: -END_MASK_LEN]))\n#create new dataset based on patients\ndff = pd.DataFrame({\"patient\": df_imgs.dir_name.values,\n                   \"image_path\": imgs,\n                   \"mask_path\": masks})\ndff[\"diagnosis\"] = dff[\"mask_path\"].apply(lambda x: pos_neg_diagnosis(x))\nprint(\"Amount of patients: \", len(set(dff.patient)))\nprint(\"Amount of records: \", len(dff))","metadata":{"_uuid":"a35d33fc-1f31-4da8-aae0-8fa42a147e02","_cell_guid":"b9093256-17c8-4758-a537-4f6c57f2322a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{"_uuid":"ca09bba9-c2af-4e36-a47e-da405a9c7132","_cell_guid":"68379745-bcfc-454c-b7d8-efa1b8defbdc","trusted":true}},{"cell_type":"code","source":"SIZE = 128\n\ntransforms = A.Compose([\n    A.Resize(width=SIZE, height=SIZE, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Normalize(p=1.0),\n    ToTensor(),\n])","metadata":{"_uuid":"b9ba983e-b70a-4fd5-b75a-3e3309752684","_cell_guid":"bf423a55-bc38-499d-9c0d-68cc8eb4d51f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Augmentation class\nclass BrainMRIDataset:\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 1])\n        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n        \n        augmented = self.transforms(image=image,\n                                   mask=mask)\n        \n        image = augmented[\"image\"]\n        mask = augmented[\"mask\"]\n        \n        return image, mask","metadata":{"_uuid":"d7e5c752-b77d-40da-918a-6fd06c938b67","_cell_guid":"488780c7-808c-4e5a-9abe-999b48b91a51","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data and DataLoaders","metadata":{"_uuid":"34c6d34c-4bc6-495a-8d02-1dc99d70290e","_cell_guid":"a8a16ae1-30e2-4527-91c5-4be7731a90a1","trusted":true}},{"cell_type":"code","source":"train_df, test_df = train_test_split(dff, stratify=dff.diagnosis, test_size=0.1,random_state=44)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\ntrain_df, val_df = train_test_split(train_df, stratify=train_df.diagnosis, test_size=0.1,random_state=44)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\nprint(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")","metadata":{"_uuid":"6a5769bc-c542-4221-9cbb-d42241feeeec","_cell_guid":"31fbbc8e-3a29-4bc1-85b4-5b4af6100f6b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_size=16\ntrain_dataset = BrainMRIDataset(train_df, transforms=transforms)\ntrain_dataloader = DataLoader(train_dataset, batch_size=b_size, num_workers=2, shuffle=True)\n\nval_dataset = BrainMRIDataset(val_df, transforms=transforms)\nval_dataloader = DataLoader(val_dataset, batch_size=b_size, num_workers=2, shuffle=False)\n\ntest_dataset = BrainMRIDataset(test_df, transforms=transforms)\ntest_dataloader = DataLoader(test_dataset, batch_size=b_size, num_workers=2, shuffle=False)","metadata":{"_uuid":"fbefb3d0-3bc1-46d5-bbf9-064e38ca8153","_cell_guid":"00fd9373-4bd7-475a-a088-47967ab241b0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display image data\nimages, masks = next(iter(train_dataloader))\nprint(images.shape, masks.shape)\n\nshow_aug(images)\nshow_aug(masks)","metadata":{"_uuid":"4f941de7-68e6-4dc7-8147-23b6b3e15cee","_cell_guid":"0ce18aba-b1f7-48c7-881b-1f379d1aed18","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Blocks","metadata":{"_uuid":"5ac76ea4-0b70-42cc-ae04-168bcdffe89f","_cell_guid":"e74e817a-e7ff-470b-b45e-45f5ca57e195","trusted":true}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self,ch_in,ch_out):\n        super(conv_block,self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\n    \n    \nclass up_conv(nn.Module):\n    def __init__(self,ch_in,ch_out,scalefactor=2,mode_='nearest',align_corners_=None):\n        super(up_conv,self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=scalefactor,mode=mode_, align_corners=align_corners_),\n            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self,x):\n        x = self.up(x)\n        return x\n    \n \n\n #for r2unet     \nclass Rec_block(nn.Module):\n    def __init__(self,ch_out,t=2):\n        super(Rec_block,self).__init__()\n        self.t = t\n        self.ch_out = ch_out\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self,x):\n        for i in range(self.t):\n\n            if i==0:\n                x1 = self.conv(x)\n            \n            x1 = self.conv(x+x1)\n        return x1\n        \nclass RRCNN_block(nn.Module):\n    def __init__(self,ch_in,ch_out,t=2):\n        super(RRCNN_block,self).__init__()\n        self.RCNN = nn.Sequential(\n            Rec_block(ch_out,t=t),\n            Rec_block(ch_out,t=t)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n    def forward(self,x):\n        x = self.Conv_1x1(x)\n        x1 = self.RCNN(x)\n        return x+x1   \n    \nclass Attention_block(nn.Module):\n    def __init__(self,F_g,F_l,F_int):\n        super(Attention_block,self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n            )\n        \n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,g,x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n\n        return x*psi\n    \n#for unet 3\nclass ThreePlusDecoder(torch.nn.Module):\n    def __init__(self, center_out_channels, level, unet_depth=5):\n        super(ThreePlusDecoder, self).__init__()\n\n        self.unet_depth = unet_depth \n        self.max_pool = torch.nn.MaxPool2d\n        self.operation_list = torch.nn.ModuleList()\n        \n        #from center(bottlneck) to the decoder in consideration\n        center_up_factor = int(2 ** (self.unet_depth - level))\n        self.operation_list.append(\n            up_conv(center_out_channels,64,scalefactor=center_up_factor,mode_='bilinear',align_corners_=True))\n\n        #from previos decoders to the decoder in consideration\n        for i in range(1, self.unet_depth - level):\n            up_scaling_factor = int(2 ** (self.unet_depth - level - i))\n            in_channels = 320\n            self.operation_list.append(\n                up_conv(in_channels,64,scalefactor=up_scaling_factor,mode_='bilinear',align_corners_=True))\n\n        #from same enocoder level to the decoder in consideration\n        current_scale = int(2 ** (self.unet_depth - level))\n        current_in_channels = center_out_channels // current_scale\n        self.current_level_operation = conv_block(current_in_channels, 64)\n        self.operation_list.append(self.current_level_operation)\n        \n        #from encoder above to the decoder in consideration\n        for i in range(1, level):\n            kernel_size = int(2 ** i)\n            in_channels = current_in_channels // int(2 ** i)\n            self.operation_list.append(\n                torch.nn.Sequential(\n                    self.max_pool(kernel_size),\n                    conv_block(in_channels, 64),\n                )\n            )\n            \n\n        self.final =  torch.nn.Conv2d(64 * self.unet_depth, 64 * self.unet_depth,kernel_size=(3, 3), padding=(1, 1))\n        self.relu = torch.nn.ReLU(inplace=True)\n        self.batchnorm=torch.nn.BatchNorm2d(64 * self.unet_depth)\n\n    def forward(self, *args):\n        out_list = []\n        for idx, element in enumerate(args):\n            out_list.append(self.operation_list[idx](element))\n\n        x = torch.cat(out_list, dim=1)\n        x= self.final(x)\n        return self.relu(self.batchnorm(x))","metadata":{"_uuid":"9517e89c-09f1-4a39-b61c-d5162e8d3f97","_cell_guid":"2717b9bf-88fd-4f14-9af2-f5b1c345a6d3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-NET Model","metadata":{"_uuid":"a69c2177-33e5-4e25-8bec-c715ca7f79df","_cell_guid":"c503d039-cdf2-4fdd-88ae-65f0cd05936b","trusted":true}},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self,img_ch=3,output_ch=1):\n        super(U_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        \n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_conv5(d5)\n        \n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1","metadata":{"_uuid":"f2a2fa90-cd7c-484b-ad29-750672a87282","_cell_guid":"473e936d-a878-4e26-9fa7-bb20cf1442c9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention U-NET Model","metadata":{"_uuid":"b70ae0c0-2150-4400-be36-70b0af4ab037","_cell_guid":"9d5c518b-d9e7-4723-9d04-34c28967c8ea","trusted":true}},{"cell_type":"code","source":"class AttentionUNet(nn.Module):\n    def __init__(self,img_ch=3,output_ch=1):\n        super(AttentionUNet,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n\n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        x4 = self.Att5(g=d5,x=x4)\n        d5 = torch.cat((x4,d5),dim=1)        \n        d5 = self.Up_conv5(d5)\n        \n        d4 = self.Up4(d5)\n        x3 = self.Att4(g=d4,x=x3)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        x2 = self.Att3(g=d3,x=x2)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        x1 = self.Att2(g=d2,x=x1)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1","metadata":{"_uuid":"f0861e8c-09a3-4541-8e4c-01f9af1136fd","_cell_guid":"e1ac02b2-984d-44fa-a864-2577a05713db","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# R2U-NET","metadata":{"_uuid":"7d08646a-36f2-4012-9dab-6f5775cb588d","_cell_guid":"c0530540-fb10-47a9-9401-8fa0a6cbc3de","trusted":true}},{"cell_type":"code","source":"class R2U_Net(nn.Module):\n    def __init__(self,img_ch=3,output_ch=1,t=2):\n        super(R2U_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.Upsample = nn.Upsample(scale_factor=2)\n\n        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.RRCNN1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.RRCNN2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.RRCNN3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.RRCNN4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.RRCNN5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_RRCNN5(d5)\n        \n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_RRCNN4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_RRCNN3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_RRCNN2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1","metadata":{"_uuid":"088bc97b-49ae-45ca-9319-aface649bcb9","_cell_guid":"1178d12b-399f-4abb-9744-d010d5c0cbc3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention R2U-NET","metadata":{"_uuid":"f81902d9-b740-4387-83eb-2f6ff3a20342","_cell_guid":"beca41d4-4d6d-4d94-bece-3a7865ce9463","trusted":true}},{"cell_type":"code","source":"class AttentionR2U_Net(nn.Module):\n    def __init__(self,img_ch=3,output_ch=1,t=2):\n        super(AttentionR2U_Net,self).__init__()\n        \n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.Upsample = nn.Upsample(scale_factor=2)\n\n        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n\n        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n        \n        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n        \n        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n        \n        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n        \n\n        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n        \n        self.Up4 = up_conv(ch_in=512,ch_out=256)\n        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n        \n        self.Up3 = up_conv(ch_in=256,ch_out=128)\n        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n        \n        self.Up2 = up_conv(ch_in=128,ch_out=64)\n        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n\n        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.RRCNN1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.RRCNN2(x2)\n        \n        x3 = self.Maxpool(x2)\n        x3 = self.RRCNN3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.RRCNN4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.RRCNN5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        x4 = self.Att5(g=d5,x=x4)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_RRCNN5(d5)\n        \n        d4 = self.Up4(d5)\n        x3 = self.Att4(g=d4,x=x3)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_RRCNN4(d4)\n\n        d3 = self.Up3(d4)\n        x2 = self.Att3(g=d3,x=x2)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_RRCNN3(d3)\n\n        d2 = self.Up2(d3)\n        x1 = self.Att2(g=d2,x=x1)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_RRCNN2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        return d1","metadata":{"_uuid":"5fd3fd7d-cdfa-44d2-9c19-f4c50416c3c9","_cell_guid":"cfcc29cd-4b57-474a-bb17-d19fd29ef23f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET 3+","metadata":{"_uuid":"1a21ca0f-e633-4c97-b0bb-bc72215ed08f","_cell_guid":"94fc8393-e556-4727-8d9f-8b029636398d","trusted":true}},{"cell_type":"code","source":"class UNet3(torch.nn.Module):\n    def __init__(self,img_ch=3,output_ch=1):\n        super(UNet3,self).__init__()\n\n\n        self.center_channels = 1024\n        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n\n        self.enc_1 = conv_block(img_ch,64)\n        self.enc_2 = conv_block(64,128)\n        self.enc_3 = conv_block(128,256)\n        self.enc_4 = conv_block(256,512)\n\n        self.center = conv_block(512, self.center_channels)\n\n        self.dec_4 = ThreePlusDecoder(self.center_channels,  level=4)\n        self.dec_3 = ThreePlusDecoder(self.center_channels, level=3)\n        self.dec_2 = ThreePlusDecoder(self.center_channels, level=2)\n        self.dec_1 = ThreePlusDecoder(self.center_channels, level=1)\n\n        self.final = torch.nn.Conv2d(320, output_ch, kernel_size=(3, 3), padding=(1, 1))\n\n    def forward(self, x):\n        enc_1 = self.enc_1(x)\n        pool_1=self.Maxpool(enc_1)\n        enc_2= self.enc_2(pool_1)\n        pool_2=self.Maxpool(enc_2)\n        enc_3= self.enc_3(pool_2)\n        pool_3=self.Maxpool(enc_3)\n        enc_4= self.enc_4(pool_3)\n        pool_4=self.Maxpool(enc_4)\n        center = self.center(pool_4)\n\n        dec_4 = self.dec_4(center, enc_4, enc_3, enc_2, enc_1)\n        dec_3 = self.dec_3(center, dec_4, enc_3, enc_2, enc_1)\n        dec_2 = self.dec_2(center, dec_4, dec_3, enc_2, enc_1)\n        dec_1 = self.dec_1(center, dec_4, dec_3, dec_2, enc_1)\n\n        x = self.final(dec_1)\n        return x","metadata":{"_uuid":"bc5660f5-5a56-476e-b797-4073ef7d7f5d","_cell_guid":"a992c1e1-be33-4a09-8d73-c9b1e7bdf48b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"_uuid":"78b80d40-231f-419e-94a9-e4f2d625fde3","_cell_guid":"651c48ab-304d-4fb4-a911-fcdb9244bce5","trusted":true}},{"cell_type":"code","source":"num_ep = 100","metadata":{"_uuid":"03363fae-cd57-4931-b952-cceeeb43a6db","_cell_guid":"c7406e22-37f4-41b5-8b4f-e6fa86acbf7f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attention-UNET","metadata":{"_uuid":"c1b486f5-b739-4757-ab23-39bd6b2380fe","_cell_guid":"22e03ad0-7ce8-4fa8-b32f-612f6a549f6c","trusted":true}},{"cell_type":"code","source":"%%time\n# atten_unet=False\nif atten_unet==True:\n    attention_unet = AttentionUNet().to(device)\n    opt_atUnet = torch.optim.Adam(attention_unet.parameters())\n    aun_lh, aun_th, aun_vh = train_model(\"Attention UNet\", attention_unet, train_dataloader, val_dataloader, BCEwithDiceLoss(), opt_atUnet, num_ep)\n    test_iou_aunet = compute_iou(attention_unet, test_dataloader)\n    print(f\"\"\"Attention U-Net\\nMean IoU of the test images - {np.around(test_iou_aunet, 2)*100}%\"\"\")\n    plot_model_history(\"Attention U-Net\", aun_th, aun_vh, num_ep)\n    plt.plot(range(num_ep), aun_lh)","metadata":{"_uuid":"319dafb1-68e6-4db2-b7bd-132d2cf5c8cd","_cell_guid":"d10b5718-a805-4a45-ba16-6fcc8a1aa5ea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNET","metadata":{"_uuid":"cfe86141-1525-4718-98a2-c5096fb8638a","_cell_guid":"3b4a866c-3709-413e-90c8-1b4b5ad1bbeb","trusted":true}},{"cell_type":"code","source":"%%time\n# unet=True\nif unet==True:\n    unet = U_Net().to(device)\n    opt_Unet = torch.optim.Adam(unet.parameters())\n    un_lh, un_th, un_vh = train_model(\"UNet\", unet, train_dataloader, val_dataloader, BCEwithDiceLoss(), opt_Unet, num_ep)\n    test_iou = compute_iou(unet, test_dataloader)\n    print(f\"\"\"U-Net\\nMean IoU of the test images - {np.around(test_iou, 2)*100}%\"\"\")\n    plot_model_history(\"U-Net\", un_th, un_vh, num_ep)\n    plt.plot(range(num_ep), un_lh)","metadata":{"_uuid":"6165cc8a-e416-490b-911a-e88b3eb853e2","_cell_guid":"928e2ea4-6e2a-4498-8141-61de8ba6d48e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## R2U-NET","metadata":{"_uuid":"ac4581c7-fae0-4676-aebf-fa2cf8870deb","_cell_guid":"d1589a3c-d008-433f-930f-ff25fc767d0e","trusted":true}},{"cell_type":"code","source":"%%time\n# uR2net=False\nif uR2net==True:\n    R2unet = R2U_Net().to(device)\n    opt_R2Unet = torch.optim.Adam(R2unet.parameters())\n    R2un_lh, R2un_th, R2un_vh = train_model(\"R2U-Net\", R2unet, train_dataloader, val_dataloader, BCEwithDiceLoss(), opt_R2Unet, num_ep)\n    test_iouR2 = compute_iou(R2unet, test_dataloader)\n    print(f\"\"\"R2U-Net\\nMean IoU of the test images - {np.around(test_iouR2, 2)*100}%\"\"\")\n    plot_model_history(\"R2U-Net\", R2un_th, R2un_vh, num_ep)\n    plt.plot(range(num_ep), R2un_lh)","metadata":{"_uuid":"c4156131-172b-4852-a3b8-52253c809391","_cell_guid":"4035e907-63c9-47f8-9f05-e6d9cb1c436c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attention R2U-NET","metadata":{"_uuid":"54c0a2c1-f93b-4067-8228-94678799377a","_cell_guid":"67c05f55-3524-4830-88ea-4f19c1ddb8dd","trusted":true}},{"cell_type":"code","source":"%%time\n# uA2net=False\nif uA2net==True:\n    AR2unet = AttentionR2U_Net().to(device)\n    opt_AR2Unet = torch.optim.Adam(AR2unet.parameters())\n    AR2un_lh, AR2un_th, AR2un_vh = train_model(\"UNet\", AR2unet, train_dataloader, val_dataloader, BCEwithDiceLoss(), opt_AR2Unet, num_ep)\n    test_iouAR2 = compute_iou(AR2unet, test_dataloader)\n    print(f\"\"\"Attention R2U-Net\\nMean IoU of the test images - {np.around(test_iouAR2, 2)*100}%\"\"\")\n    plot_model_history(\"Attention R2U-Net\", AR2un_th, AR2un_vh, num_ep)\n    plt.plot(range(num_ep), AR2un_lh)","metadata":{"_uuid":"faadf577-c5c4-43c9-9bf8-b792fa4e0015","_cell_guid":"dd93b0db-299d-4b2a-92a8-20c8da234889","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNET 3","metadata":{"_uuid":"f99e672f-19c9-4729-a429-6677e4e743c2","_cell_guid":"a97a385b-4ec3-4bcd-8e99-136f0edd5442","trusted":true}},{"cell_type":"code","source":"%%time\n# u3net=False\nif u3net==True:\n    unet3 = UNet3().to(device)\n    opt_Unet3 = torch.optim.Adam(unet3.parameters())\n    u3_lh,u3_th, u3_vh = train_model(\"UNet3\", unet3, train_dataloader, val_dataloader, BCEwithDiceLoss(), opt_Unet3, num_ep)\n    test_iou3 = compute_iou(unet3, test_dataloader)\n    print(f\"\"\"U-Net 3 \\nMean IoU of the test images - {np.around(test_iou3, 2)*100}%\"\"\")\n    plot_model_history(\"U-Net 3\", u3_th, u3_vh, num_ep)\n    plt.plot(range(num_ep),u3_lh)","metadata":{"_uuid":"d0eb2f57-8cc1-4b3c-bbfb-d0970a18b40d","_cell_guid":"d324383c-5dd5-4d73-928e-2cd89e3092a0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}